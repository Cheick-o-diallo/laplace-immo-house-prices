{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè† House Price Prediction - Notebook 3: Modeling\n",
    "## Entra√Ænement et comparaison de mod√®les de r√©gression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, TargetEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 90)\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Pour la reproductibilit√©\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Chargement et pr√©paration des donn√©es\n",
    "**Important**: Nous reproduisons le preprocessing effectu√© dans le notebook 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des donn√©es\n",
    "df = pd.read_csv(\"../src/data/train.csv\")\n",
    "print(f\"Shape initiale: {df.shape}\")\n",
    "print(f\"Nombre de valeurs manquantes: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 1.1 Gestion des valeurs manquantes\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "# Variables cat√©gorielles ‚Üí \"None\"\n",
    "na_as_none = [\n",
    "    \"Alley\", \"BsmtQual\", \"BsmtCond\", \"BsmtExposure\", \"BsmtFinType1\", \"BsmtFinType2\",\n",
    "    \"FireplaceQu\", \"GarageType\", \"GarageFinish\", \"GarageQual\", \"GarageCond\",\n",
    "    \"PoolQC\", \"Fence\", \"MiscFeature\", \"MasVnrType\", \"Electrical\"\n",
    "]\n",
    "\n",
    "for col in na_as_none:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(\"None\")\n",
    "\n",
    "# Variables num√©riques ‚Üí m√©diane\n",
    "for col in df.select_dtypes(include=[\"float64\", \"int64\"]).columns:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "print(f\"Valeurs manquantes apr√®s imputation: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 1.2 Transformation de la variable cible\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "# Log-transformation de SalePrice pour normaliser\n",
    "df['LogSalePrice'] = np.log1p(df['SalePrice'])\n",
    "\n",
    "print(\"Distribution avant/apr√®s transformation:\")\n",
    "print(f\"Skewness SalePrice: {df['SalePrice'].skew():.3f}\")\n",
    "print(f\"Skewness LogSalePrice: {df['LogSalePrice'].skew():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 1.3 Encodage des variables cat√©gorielles\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "# One-Hot Encoding pour variables nominales\n",
    "cols_to_ohe = [\n",
    "    \"MSSubClass\", \"MSZoning\", \"Street\", \"Alley\", \"LotShape\", \"LandContour\",\n",
    "    \"Utilities\", \"LotConfig\", \"LandSlope\", \"Condition1\", \"Condition2\",\n",
    "    \"BldgType\", \"HouseStyle\", \"RoofStyle\", \"RoofMatl\", \"MasVnrType\",\n",
    "    \"BsmtExposure\", \"BsmtFinType1\", \"BsmtFinType2\", \"Heating\", \"CentralAir\",\n",
    "    \"Electrical\", \"Functional\", \"GarageType\", \"PavedDrive\", \"SaleType\",\n",
    "    \"SaleCondition\", \"Foundation\", \"Fence\", \"MiscFeature\"\n",
    "]\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded_ohe = ohe.fit_transform(df[cols_to_ohe])\n",
    "encoded_ohe_df = pd.DataFrame(\n",
    "    encoded_ohe,\n",
    "    columns=ohe.get_feature_names_out(cols_to_ohe),\n",
    "    index=df.index\n",
    ")\n",
    "df = pd.concat([df.drop(columns=cols_to_ohe), encoded_ohe_df], axis=1)\n",
    "\n",
    "print(f\"Shape apr√®s One-Hot Encoding: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding pour variables ordinales (qualit√©)\n",
    "quality_map = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'None': 0}\n",
    "\n",
    "cols_quality = [\n",
    "    \"ExterQual\", \"ExterCond\", \"BsmtQual\", \"BsmtCond\", \"HeatingQC\",\n",
    "    \"KitchenQual\", \"FireplaceQu\", \"GarageQual\", \"GarageCond\", \"PoolQC\"\n",
    "]\n",
    "\n",
    "for col in cols_quality:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].map(quality_map)\n",
    "\n",
    "# GarageFinish\n",
    "finished_map = {'Fin': 3, 'RFn': 2, 'Unf': 1, 'None': 0}\n",
    "if 'GarageFinish' in df.columns:\n",
    "    df['GarageFinish'] = df['GarageFinish'].map(finished_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Encoding pour variables √† haute cardinalit√©\n",
    "# Note: Nous le ferons APR√àS le split pour √©viter le data leakage\n",
    "cols_to_target = [\"Neighborhood\", \"Exterior1st\", \"Exterior2nd\"]\n",
    "\n",
    "print(f\"Variables √† encoder avec Target Encoding: {cols_to_target}\")\n",
    "print(f\"Cardinalit√©s:\")\n",
    "for col in cols_to_target:\n",
    "    if col in df.columns:\n",
    "        print(f\"  {col}: {df[col].nunique()} modalit√©s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pr√©paration Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©paration X et y\n",
    "# On retire: Id, SalePrice (original), LogSalePrice (target)\n",
    "cols_to_drop = ['Id', 'SalePrice', 'LogSalePrice']\n",
    "cols_to_drop = [c for c in cols_to_drop if c in df.columns]\n",
    "\n",
    "X = df.drop(columns=cols_to_drop)\n",
    "y = df['LogSalePrice']\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"\\nTypes de donn√©es dans X:\")\n",
    "print(X.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Encoding AVANT le split (pour simplification)\n",
    "# Dans un contexte production, on ferait √ßa dans une pipeline avec CV\n",
    "tg_encoder = TargetEncoder(\n",
    "    categories='auto',\n",
    "    target_type='continuous',\n",
    "    smooth='auto',\n",
    "    cv=5,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "if all(col in X.columns for col in cols_to_target):\n",
    "    X[cols_to_target] = tg_encoder.fit_transform(X[cols_to_target], y)\n",
    "    print(\"Target Encoding appliqu√© avec succ√®s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rification qu'il ne reste plus de variables cat√©gorielles\n",
    "object_cols = X.select_dtypes(include='object').columns\n",
    "if len(object_cols) > 0:\n",
    "    print(f\"‚ö†Ô∏è Variables cat√©gorielles restantes: {list(object_cols)}\")\n",
    "else:\n",
    "    print(\"‚úÖ Toutes les variables sont num√©riques\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardisation (important pour Ridge, Lasso, ElasticNet)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Conversion en DataFrame pour garder les noms de colonnes\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"‚úÖ Donn√©es standardis√©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fonctions utilitaires pour l'√©valuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    \"\"\"\n",
    "    √âvalue un mod√®le et retourne les m√©triques.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionnaire contenant toutes les m√©triques\n",
    "    \"\"\"\n",
    "    # Pr√©dictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # M√©triques sur train\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    \n",
    "    # M√©triques sur test\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Cross-validation (5-fold)\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "    cv_scores = -cross_val_score(\n",
    "        model, X_train, y_train,\n",
    "        cv=kfold,\n",
    "        scoring='neg_root_mean_squared_error'\n",
    "    )\n",
    "    cv_rmse_mean = cv_scores.mean()\n",
    "    cv_rmse_std = cv_scores.std()\n",
    "    \n",
    "    results = {\n",
    "        'model': model_name,\n",
    "        'train_rmse': train_rmse,\n",
    "        'train_mae': train_mae,\n",
    "        'train_r2': train_r2,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_mae': test_mae,\n",
    "        'test_r2': test_r2,\n",
    "        'cv_rmse_mean': cv_rmse_mean,\n",
    "        'cv_rmse_std': cv_rmse_std,\n",
    "        'overfitting': train_rmse - test_rmse  # N√©gatif = bon signe\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_results(results):\n",
    "    \"\"\"\n",
    "    Affiche les r√©sultats de mani√®re format√©e.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Mod√®le: {results['model']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nüìä Performance sur Train:\")\n",
    "    print(f\"  RMSE: {results['train_rmse']:.4f}\")\n",
    "    print(f\"  MAE:  {results['train_mae']:.4f}\")\n",
    "    print(f\"  R¬≤:   {results['train_r2']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nüìä Performance sur Test:\")\n",
    "    print(f\"  RMSE: {results['test_rmse']:.4f}\")\n",
    "    print(f\"  MAE:  {results['test_mae']:.4f}\")\n",
    "    print(f\"  R¬≤:   {results['test_r2']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nüîÑ Cross-Validation (5-fold):\")\n",
    "    print(f\"  RMSE: {results['cv_rmse_mean']:.4f} ¬± {results['cv_rmse_std']:.4f}\")\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è Overfitting Check:\")\n",
    "    print(f\"  Train RMSE - Test RMSE: {results['overfitting']:.4f}\")\n",
    "    if results['overfitting'] < -0.01:\n",
    "        print(\"  ‚úÖ Pas d'overfitting d√©tect√©\")\n",
    "    elif results['overfitting'] > 0.02:\n",
    "        print(\"  ‚ö†Ô∏è Overfitting possible\")\n",
    "    else:\n",
    "        print(\"  ‚úì Performance stable\")\n",
    "    print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Entra√Ænement des mod√®les\n",
    "Nous testons 6 mod√®les diff√©rents avec diff√©rentes approches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire pour stocker tous les r√©sultats\n",
    "all_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Linear Regression (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîπ Entra√Ænement: Linear Regression (Baseline)\")\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "lr_results = evaluate_model(lr, X_train_scaled, y_train, X_test_scaled, y_test, \"Linear Regression\")\n",
    "all_results.append(lr_results)\n",
    "print_results(lr_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Ridge Regression (L2 Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîπ Entra√Ænement: Ridge Regression\")\n",
    "ridge = Ridge(alpha=10.0, random_state=RANDOM_STATE)\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "ridge_results = evaluate_model(ridge, X_train_scaled, y_train, X_test_scaled, y_test, \"Ridge\")\n",
    "all_results.append(ridge_results)\n",
    "print_results(ridge_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Lasso Regression (L1 Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîπ Entra√Ænement: Lasso Regression\")\n",
    "lasso = Lasso(alpha=0.001, max_iter=10000, random_state=RANDOM_STATE)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "lasso_results = evaluate_model(lasso, X_train_scaled, y_train, X_test_scaled, y_test, \"Lasso\")\n",
    "all_results.append(lasso_results)\n",
    "print_results(lasso_results)\n",
    "\n",
    "# Nombre de coefficients non-nuls (feature selection)\n",
    "n_nonzero = np.sum(lasso.coef_ != 0)\n",
    "print(f\"\\nüìå Features s√©lectionn√©es par Lasso: {n_nonzero}/{len(lasso.coef_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 ElasticNet (L1 + L2 Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîπ Entra√Ænement: ElasticNet\")\n",
    "elastic = ElasticNet(alpha=0.001, l1_ratio=0.5, max_iter=10000, random_state=RANDOM_STATE)\n",
    "elastic.fit(X_train_scaled, y_train)\n",
    "\n",
    "elastic_results = evaluate_model(elastic, X_train_scaled, y_train, X_test_scaled, y_test, \"ElasticNet\")\n",
    "all_results.append(elastic_results)\n",
    "print_results(elastic_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Random Forest (Ensemble - Bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîπ Entra√Ænement: Random Forest\")\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)  # Pas besoin de scaling pour RF\n",
    "\n",
    "rf_results = evaluate_model(rf, X_train, y_train, X_test, y_test, \"Random Forest\")\n",
    "all_results.append(rf_results)\n",
    "print_results(rf_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6 Gradient Boosting (Ensemble - Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîπ Entra√Ænement: Gradient Boosting\")\n",
    "gb = GradientBoostingRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    subsample=0.8,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "gb_results = evaluate_model(gb, X_train, y_train, X_test, y_test, \"Gradient Boosting\")\n",
    "all_results.append(gb_results)\n",
    "print_results(gb_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.7 XGBoost (Optimized Gradient Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîπ Entra√Ænement: XGBoost\")\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    min_child_weight=3,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    gamma=0,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "xgb_results = evaluate_model(xgb, X_train, y_train, X_test, y_test, \"XGBoost\")\n",
    "all_results.append(xgb_results)\n",
    "print_results(xgb_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Comparaison des mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation du DataFrame de comparaison\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df = results_df.sort_values('test_rmse')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä TABLEAU COMPARATIF DES MOD√àLES (class√© par RMSE test)\")\n",
    "print(\"=\"*80)\n",
    "display(results_df[[\n",
    "    'model', 'test_rmse', 'test_r2', 'cv_rmse_mean', 'cv_rmse_std', 'overfitting'\n",
    "]].round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation comparative\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# RMSE Comparison\n",
    "models = results_df['model']\n",
    "x_pos = np.arange(len(models))\n",
    "\n",
    "axes[0].barh(x_pos, results_df['test_rmse'], color='steelblue', alpha=0.7, label='Test RMSE')\n",
    "axes[0].barh(x_pos, results_df['cv_rmse_mean'], color='coral', alpha=0.5, label='CV RMSE')\n",
    "axes[0].set_yticks(x_pos)\n",
    "axes[0].set_yticklabels(models)\n",
    "axes[0].set_xlabel('RMSE (log scale)')\n",
    "axes[0].set_title('Comparaison des RMSE')\n",
    "axes[0].legend()\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# R¬≤ Comparison\n",
    "axes[1].barh(x_pos, results_df['test_r2'], color='green', alpha=0.7)\n",
    "axes[1].set_yticks(x_pos)\n",
    "axes[1].set_yticklabels(models)\n",
    "axes[1].set_xlabel('R¬≤ Score')\n",
    "axes[1].set_title('Comparaison des R¬≤')\n",
    "axes[1].set_xlim([0.7, 1.0])\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "# Overfitting Analysis\n",
    "colors = ['red' if x > 0.02 else 'orange' if x > 0 else 'green' for x in results_df['overfitting']]\n",
    "axes[2].barh(x_pos, results_df['overfitting'], color=colors, alpha=0.7)\n",
    "axes[2].axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "axes[2].set_yticks(x_pos)\n",
    "axes[2].set_yticklabels(models)\n",
    "axes[2].set_xlabel('Train RMSE - Test RMSE')\n",
    "axes[2].set_title('Analyse Overfitting')\n",
    "axes[2].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Analyse des pr√©dictions du meilleur mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifier le meilleur mod√®le\n",
    "best_model_name = results_df.iloc[0]['model']\n",
    "print(f\"\\nüèÜ Meilleur mod√®le: {best_model_name}\")\n",
    "print(f\"   Test RMSE: {results_df.iloc[0]['test_rmse']:.4f}\")\n",
    "print(f\"   Test R¬≤: {results_df.iloc[0]['test_r2']:.4f}\")\n",
    "\n",
    "# R√©cup√©rer le mod√®le correspondant\n",
    "best_model_dict = {\n",
    "    'Linear Regression': lr,\n",
    "    'Ridge': ridge,\n",
    "    'Lasso': lasso,\n",
    "    'ElasticNet': elastic,\n",
    "    'Random Forest': rf,\n",
    "    'Gradient Boosting': gb,\n",
    "    'XGBoost': xgb\n",
    "}\n",
    "\n",
    "best_model = best_model_dict[best_model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©dictions du meilleur mod√®le\n",
    "if best_model_name in ['Linear Regression', 'Ridge', 'Lasso', 'ElasticNet']:\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "else:\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Visualisation des pr√©dictions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1. Actual vs Predicted\n",
    "axes[0].scatter(y_test, y_pred, alpha=0.5, s=30)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0].set_xlabel('Prix r√©el (log)')\n",
    "axes[0].set_ylabel('Prix pr√©dit (log)')\n",
    "axes[0].set_title(f'{best_model_name}: Actual vs Predicted')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Residuals\n",
    "residuals = y_test - y_pred\n",
    "axes[1].scatter(y_pred, residuals, alpha=0.5, s=30)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Prix pr√©dit (log)')\n",
    "axes[1].set_ylabel('R√©sidus')\n",
    "axes[1].set_title('Residual Plot')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Distribution des r√©sidus\n",
    "axes[2].hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[2].axvline(x=0, color='r', linestyle='--', lw=2)\n",
    "axes[2].set_xlabel('R√©sidus')\n",
    "axes[2].set_ylabel('Fr√©quence')\n",
    "axes[2].set_title('Distribution des r√©sidus')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nStatistiques des r√©sidus:\")\n",
    "print(f\"  Moyenne: {residuals.mean():.6f}\")\n",
    "print(f\"  M√©diane: {residuals.median():.6f}\")\n",
    "print(f\"  √âcart-type: {residuals.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Feature Importance (pour mod√®les tree-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model_name in ['Random Forest', 'Gradient Boosting', 'XGBoost']:\n",
    "    # R√©cup√©ration des importances\n",
    "    if hasattr(best_model, 'feature_importances_'):\n",
    "        importances = best_model.feature_importances_\n",
    "        feature_names = X_train.columns\n",
    "        \n",
    "        # Cr√©ation du DataFrame\n",
    "        feature_importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': importances\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        # Top 20 features\n",
    "        top_features = feature_importance_df.head(20)\n",
    "        \n",
    "        # Visualisation\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.barh(range(len(top_features)), top_features['importance'], color='steelblue', alpha=0.7)\n",
    "        plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "        plt.xlabel('Importance')\n",
    "        plt.title(f'Top 20 Features - {best_model_name}')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.grid(True, alpha=0.3, axis='x')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nTop 10 features les plus importantes:\")\n",
    "        display(top_features.head(10))\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Feature importance n'est pas disponible pour {best_model_name}\")\n",
    "    print(\"Pour les mod√®les lin√©aires, vous pouvez examiner les coefficients.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Sauvegarde du meilleur mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du mod√®le\n",
    "with open('../models/best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "# Sauvegarde du scaler si n√©cessaire\n",
    "if best_model_name in ['Linear Regression', 'Ridge', 'Lasso', 'ElasticNet']:\n",
    "    with open('../models/scaler.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    print(\"‚úÖ Scaler sauvegard√©\")\n",
    "\n",
    "# Sauvegarde des r√©sultats\n",
    "results_df.to_csv('../models/model_comparison.csv', index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Meilleur mod√®le sauvegard√©: {best_model_name}\")\n",
    "print(f\"   Fichier: ../models/best_model.pkl\")\n",
    "print(f\"   R√©sultats: ../models/model_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. R√©sum√© et Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìã R√âSUM√â DE LA MOD√âLISATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüéØ Objectif: Pr√©dire le prix de vente des maisons (SalePrice)\")\n",
    "print(f\"\\nüìä Donn√©es:\")\n",
    "print(f\"   - Dataset: {len(df)} maisons\")\n",
    "print(f\"   - Features: {X.shape[1]} variables apr√®s preprocessing\")\n",
    "print(f\"   - Split: {len(X_train)} train / {len(X_test)} test\")\n",
    "\n",
    "print(f\"\\nüîß Preprocessing:\")\n",
    "print(f\"   - Imputation des valeurs manquantes\")\n",
    "print(f\"   - Log-transformation de SalePrice (skewness: {df['SalePrice'].skew():.3f} ‚Üí {df['LogSalePrice'].skew():.3f})\")\n",
    "print(f\"   - One-Hot Encoding pour variables nominales\")\n",
    "print(f\"   - Label Encoding pour variables ordinales\")\n",
    "print(f\"   - Target Encoding pour haute cardinalit√©\")\n",
    "print(f\"   - Standardisation pour mod√®les lin√©aires\")\n",
    "\n",
    "print(f\"\\nüèÜ Meilleur Mod√®le: {best_model_name}\")\n",
    "print(f\"   - Test RMSE: {results_df.iloc[0]['test_rmse']:.4f}\")\n",
    "print(f\"   - Test R¬≤: {results_df.iloc[0]['test_r2']:.4f}\")\n",
    "print(f\"   - CV RMSE: {results_df.iloc[0]['cv_rmse_mean']:.4f} ¬± {results_df.iloc[0]['cv_rmse_std']:.4f}\")\n",
    "\n",
    "print(f\"\\nüí° Interpr√©tation du RMSE:\")\n",
    "rmse_dollars = np.expm1(results_df.iloc[0]['test_rmse'])  # Conversion de log √† dollars\n",
    "print(f\"   RMSE en dollars: ${rmse_dollars:,.0f}\")\n",
    "print(f\"   (Erreur moyenne de pr√©diction)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéì Prochaine √©tape: Notebook 4 - √âvaluation finale\n",
    "\n",
    "Dans le prochain notebook, nous allons:\n",
    "- Analyser en d√©tail les performances du meilleur mod√®le\n",
    "- Effectuer une analyse des erreurs\n",
    "- Comparer performance vs complexit√©\n",
    "- Justifier le choix final du mod√®le\n",
    "- Discuter des pistes d'am√©lioration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
